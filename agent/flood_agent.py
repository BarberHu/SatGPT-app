"""
æ´ªæ°´æ™ºèƒ½ä½“ - ä½¿ç”¨ LangGraph æ„å»º
åŸºäº CopilotKit AG-UI åè®®
æ”¯æŒ Human-in-the-Loop (HITL) é€šè¿‡ interrupt å®ç°

é‡æ„ç‰ˆæœ¬ï¼šé‡‡ç”¨æ¸…æ™°çš„èŠ‚ç‚¹åˆ†ç¦»è®¾è®¡
- entry_node: å…¥å£è·¯ç”±ï¼Œåˆ¤æ–­ç”¨æˆ·æ„å›¾
- chat_node: é€šç”¨èŠå¤©ï¼Œå¤„ç†å·¥å…·è°ƒç”¨
- extraction_node: ä¿¡æ¯æå–ï¼Œä»æœç´¢ç»“æœæå–ç»“æ„åŒ–æ•°æ®
- confirmation_node: ç”¨æˆ·ç¡®è®¤ (HITL)
- processing_node: æ•°æ®å¤„ç†ï¼Œåœ°ç†ç¼–ç  + æŠ¥å‘Šç”Ÿæˆ
"""
import os
import json
import requests
from typing import Literal, Optional, Dict, Any

from dotenv import load_dotenv
from langchain.tools import tool
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, AIMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, interrupt

from state import FloodAgentState
from prompts import SYSTEM_PROMPT, FLOOD_REPORT_TEMPLATE, REPORT_GENERATION_PROMPT

load_dotenv()

# é…ç½®ä»£ç†
http_proxy = os.getenv("HTTP_PROXY")
https_proxy = os.getenv("HTTPS_PROXY")
if http_proxy:
    os.environ["HTTP_PROXY"] = http_proxy
if https_proxy:
    os.environ["HTTPS_PROXY"] = https_proxy


# ============== å†…éƒ¨å‡½æ•° ==============

def _classify_location_type(location_name: str) -> dict:
    """
    ä½¿ç”¨LLMåˆ¤æ–­åœ°åç±»å‹
    
    è¿”å›:
    - type: "administrative" (è¡Œæ”¿åŒºåŸŸ) æˆ– "composite" (ç»„åˆ/è‡ªç„¶åŒºåŸŸ)
    - reason: åˆ¤æ–­åŸå› 
    """
    try:
        model = _get_model()
        
        prompt = f"""Please determine the type of the following place name:

Place name: {location_name}

Criteria:
1. "administrative" - An independent administrative region, such as: country, province/state, city, county, district, etc., with clearly defined administrative boundaries
   Examples: Beijing, Germany, California, Tokyo, Paris

2. "composite" - A composite place name, geographic location, or natural region, including:
   - Combinations of multiple administrative regions: Jing-Jin-Ji, Yangtze River Delta, Pearl River Delta, EU
   - Geographic location concepts: North China, Southeast Asia, Middle East
   - Natural geographic regions: Yellow River Basin, Amazon Basin, Alpine Region
   - Trans-administrative geographic units: Mississippi River Basin, Danube Plain

Please return strictly in the following JSON format, do not include any other text:
```json
{{"type": "administrative or composite", "reason": "brief explanation"}}
```"""

        response = model.invoke([HumanMessage(content=prompt)])
        content = response.content
        
        # æå–JSON
        if "```json" in content:
            json_str = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            json_str = content.split("```")[1].split("```")[0]
        else:
            json_str = content
        
        data = json.loads(json_str.strip())
        location_type = data.get("type", "administrative")
        reason = data.get("reason", "")
        
        print(f"ğŸ” åœ°åç±»å‹åˆ¤æ–­: {location_name} -> {location_type} ({reason})")
        return {"type": location_type, "reason": reason}
        
    except Exception as e:
        print(f"âš ï¸ LLMåˆ¤æ–­åœ°åç±»å‹å¤±è´¥: {e}ï¼Œé»˜è®¤ä¸ºè¡Œæ”¿åŒºåŸŸ")
        return {"type": "administrative", "reason": "åˆ¤æ–­å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼"}


def _generate_geojson_with_llm(location_name: str) -> Optional[Dict[str, Any]]:
    """
    ä½¿ç”¨LLMç”Ÿæˆç»„åˆåŒºåŸŸçš„å¤§è‡´GeoJSONè¾¹ç•Œ
    é€‚ç”¨äºï¼šç»„åˆåœ°åã€åœ°ç†åŒºä½ã€è‡ªç„¶åŒºåŸŸç­‰éæ ‡å‡†è¡Œæ”¿åŒºåŸŸ
    """
    try:
        model = _get_model()
        
        prompt = f"""Please generate an approximate GeoJSON boundary for the following geographic region.

Geographic region name: {location_name}

Requirements:
1. Generate a simplified Polygon boundary with 4-8 vertices to represent the approximate extent
2. Coordinates should be in [longitude, latitude] format using WGS84 coordinate system
3. The polygon must be closed (first and last coordinates must be the same)
4. Also provide the center point coordinates and bounding box

Please return strictly in the following JSON format, do not include any other text:

```json
{{
    "center": [longitude, latitude],
    "bounds": {{
        "west": westernmost_longitude,
        "south": southernmost_latitude,
        "east": easternmost_longitude,
        "north": northernmost_latitude
    }},
    "geometry": {{
        "type": "Polygon",
        "coordinates": [[[lon1, lat1], [lon2, lat2], ..., [lon1, lat1]]]
    }}
}}
```"""

        response = model.invoke([HumanMessage(content=prompt)])
        content = response.content
        
        # æå–JSON
        if "```json" in content:
            json_str = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            json_str = content.split("```")[1].split("```")[0]
        else:
            json_str = content
        
        data = json.loads(json_str.strip())
        
        # éªŒè¯æ•°æ®ç»“æ„
        if not all(k in data for k in ['center', 'bounds', 'geometry']):
            raise ValueError("Missing required fields")
        
        # æ„å»ºGeoJSON Feature
        geojson_feature = {
            'type': 'Feature',
            'properties': {
                'name': location_name,
                'type': 'composite_region',
                'source': 'LLM_generated'
            },
            'geometry': data['geometry']
        }
        
        print(f"âœ… LLMæˆåŠŸç”Ÿæˆåœ°ç†æ•°æ®: {location_name}")
        return {
            "location": location_name,
            "coordinates": data['center'],
            "bounds": data['bounds'],
            "geojson": geojson_feature,
            "type": "composite_region",
            "source": "LLM_generated"
        }
        
    except Exception as e:
        print(f"âŒ LLMç”ŸæˆGeoJSONå¤±è´¥: {e}")
        return None


def _get_location_from_nominatim(location_name: str) -> Optional[Dict[str, Any]]:
    """
    ä»Nominatim APIè·å–è¡Œæ”¿åŒºåŸŸçš„GeoJSON
    ä¸é™åˆ¶å›½å®¶èŒƒå›´
    """
    try:
        import time
        time.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        
        nominatim_url = "https://nominatim.openstreetmap.org/search"
        params = {
            'q': location_name,
            'format': 'geojson',
            'polygon_geojson': 1,
            'limit': 1,
            'accept-language': 'en,zh-CN'  # Prefer English, then Chinese
        }
        
        headers = {
            'User-Agent': 'FloodAgent/1.0 (flood monitoring application)'
        }
        
        response = requests.get(nominatim_url, params=params, headers=headers, timeout=15)
        response.raise_for_status()
        
        data = response.json()
        
        if not data.get('features'):
            return None
        
        feature = data['features'][0]
        geometry = feature.get('geometry')
        properties = feature.get('properties', {})
        
        # è®¡ç®—è¾¹ç•Œæ¡†å’Œä¸­å¿ƒç‚¹
        bounds = None
        center = None
        
        if geometry and geometry.get('coordinates'):
            if geometry['type'] == 'Point':
                lon, lat = geometry['coordinates']
                buffer = 0.5  # å¯¹äºç‚¹ï¼Œåˆ›å»ºè¾ƒå¤§çš„ç¼“å†²åŒº
                bounds = {
                    'west': lon - buffer,
                    'south': lat - buffer,
                    'east': lon + buffer,
                    'north': lat + buffer
                }
                center = [lon, lat]
            else:
                def extract_coords(coords, result_coords=None):
                    if result_coords is None:
                        result_coords = []
                    if isinstance(coords[0], (int, float)):
                        result_coords.append(coords)
                    else:
                        for coord in coords:
                            extract_coords(coord, result_coords)
                    return result_coords
                
                all_coords = extract_coords(geometry['coordinates'])
                if all_coords:
                    lons = [coord[0] for coord in all_coords]
                    lats = [coord[1] for coord in all_coords]
                    bounds = {
                        'west': min(lons),
                        'south': min(lats),
                        'east': max(lons),
                        'north': max(lats)
                    }
                    center = [
                        (bounds['west'] + bounds['east']) / 2,
                        (bounds['south'] + bounds['north']) / 2
                    ]
        
        geojson_feature = {
            'type': 'Feature',
            'properties': {
                'name': properties.get('display_name', location_name),
                'type': properties.get('type'),
                'class': properties.get('class')
            },
            'geometry': geometry
        }
        
        return {
            "location": properties.get('display_name', location_name),
            "coordinates": center if center else [0.0, 0.0],
            "bounds": bounds if bounds else {"south": -90, "north": 90, "west": -180, "east": 180},
            "geojson": geojson_feature,
            "type": properties.get('type', 'administrative'),
            "source": "Nominatim/OpenStreetMap"
        }
        
    except Exception as e:
        print(f"âš ï¸ NominatimæŸ¥è¯¢å¤±è´¥: {e}")
        return None


def _get_location_coordinates_internal(location_name: str) -> Optional[Dict[str, Any]]:
    """
    æ™ºèƒ½åœ°ç†ç¼–ç å‡½æ•°
    
    ç­–ç•¥ï¼š
    1. ä½¿ç”¨LLMåˆ¤æ–­åœ°åç±»å‹ï¼ˆè¡Œæ”¿åŒºåŸŸ vs ç»„åˆ/è‡ªç„¶åŒºåŸŸï¼‰
    2. è¡Œæ”¿åŒºåŸŸ â†’ ä½¿ç”¨Nominatim APIè·å–ç²¾ç¡®GeoJSON
    3. ç»„åˆ/è‡ªç„¶åŒºåŸŸ â†’ ä½¿ç”¨LLMç”Ÿæˆå¤§è‡´GeoJSON
    4. å¦‚æœNominatimå¤±è´¥ï¼Œå›é€€åˆ°LLMç”Ÿæˆ
    """
    print(f"ğŸ“ æ­£åœ¨è·å–åœ°ç†æ•°æ®: {location_name}")
    
    # ä½¿ç”¨LLMåˆ¤æ–­åœ°åç±»å‹
    classification = _classify_location_type(location_name)
    is_composite = classification["type"] == "composite"
    
    if is_composite:
        print(f"ğŸ” æ£€æµ‹åˆ°ç»„åˆåŒºåŸŸï¼Œä½¿ç”¨LLMç”ŸæˆGeoJSON: {location_name}")
        result = _generate_geojson_with_llm(location_name)
        if result:
            return result
        # LLMå¤±è´¥æ—¶å°è¯•Nominatim
        print(f"âš ï¸ LLMç”Ÿæˆå¤±è´¥ï¼Œå°è¯•Nominatim...")
    
    # å°è¯•Nominatim API
    print(f"ğŸŒ å°è¯•ä»Nominatimè·å–: {location_name}")
    result = _get_location_from_nominatim(location_name)
    
    if result:
        print(f"âœ… æˆåŠŸè·å–åœ°ç†æ•°æ®: {location_name}")
        return result
    
    # Nominatimå¤±è´¥ï¼Œå°è¯•LLM
    if not is_composite:
        print(f"âš ï¸ Nominatimæœªæ‰¾åˆ°ï¼Œå°è¯•LLMç”Ÿæˆ: {location_name}")
        result = _generate_geojson_with_llm(location_name)
        if result:
            return result
    
    # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
    print(f"âŒ æ— æ³•è·å–åœ°ç†æ•°æ®: {location_name}")
    return {
        "location": location_name,
        "coordinates": [0.0, 0.0],
        "bounds": {"south": -90, "north": 90, "west": -180, "east": 180},
        "geojson": None,
        "error": f"Unable to retrieve geographic information for '{location_name}'"
    }


def _get_model() -> ChatOpenAI:
    """è·å– LLM æ¨¡å‹å®ä¾‹"""
    return ChatOpenAI(
        model=os.getenv("LLM_MODEL", "gpt-4o-mini"),
        api_key=os.getenv("OPENAI_API_KEY", ""),
        base_url=os.getenv("OPENAI_API_BASE"),
        temperature=0.7
    )


def _should_route_to_tool_node(tool_calls, fe_tools) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·¯ç”±åˆ°å·¥å…·èŠ‚ç‚¹"""
    if not tool_calls:
        return False
    
    fe_tool_names = {tool.get("name") for tool in fe_tools}
    
    for tool_call in tool_calls:
        tool_name = (
            tool_call.get("name")
            if isinstance(tool_call, dict)
            else getattr(tool_call, "name", None)
        )
        if tool_name in fe_tool_names:
            return False
    
    return True


def _extract_flood_info_from_content(content: str) -> dict:
    """ä» LLM å“åº”å†…å®¹ä¸­æå–æ´ªæ°´ä¿¡æ¯"""
    updates = {}
    try:
        if "```json" in content:
            json_str = content.split("```json")[1].split("```")[0]
            data = json.loads(json_str.strip())
            
            field_names = ["event", "event_description", "location", 
                          "pre_date", "peek_date", "after_date", "stage"]
            for field in field_names:
                if data.get(field):
                    updates[field] = data[field]
            
            # æå–åæ ‡å’Œè¾¹ç•Œ
            if data.get("coordinates") and isinstance(data["coordinates"], list) and len(data["coordinates"]) == 2:
                updates["coordinates"] = data["coordinates"]
            if data.get("bounds") and isinstance(data["bounds"], dict):
                required_keys = ["west", "east", "south", "north"]
                if all(k in data["bounds"] for k in required_keys):
                    updates["bounds"] = data["bounds"]
    except (json.JSONDecodeError, IndexError, KeyError):
        pass
    
    return updates


def _format_sources_text(sources: list) -> str:
    """æ ¼å¼åŒ–æ¥æºä¿¡æ¯ä¸º Markdown æ–‡æœ¬"""
    if not sources:
        return "*This report is compiled from publicly available online sources*"
    
    lines = []
    # æ˜¾ç¤ºæ‰€æœ‰æ¥æº
    for i, source in enumerate(sources, 1):
        title = source.get("title", "Unknown source")
        url = source.get("url", "#")
        lines.append(f"{i}. [{title}]({url})")
    
    result = "\n".join(lines) if lines else "*This report is compiled from publicly available online sources*"
    
    # å¦‚æœæ¥æºä¸è¶³10æ¡ï¼Œæ·»åŠ è¯´æ˜
    if len(sources) < 10:
        result = f"**Note**: Due to limited public reporting on this flood event, the number of available sources is relatively small ({len(sources)} in total). The following analysis is based on the currently available authoritative sources.\n\n" + result
    
    return result


def _has_complete_flood_info(state: FloodAgentState) -> bool:
    """æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„æ´ªæ°´äº‹ä»¶ä¿¡æ¯"""
    return all([
        state.get("event"),
        state.get("pre_date"),
        state.get("peek_date"),
        state.get("after_date"),
        state.get("location")
    ])


# ============== å·¥å…·å®šä¹‰ ==============

# å…¨å±€å˜é‡ç”¨äºä¸´æ—¶å­˜å‚¨æœç´¢æ¥æºä¿¡æ¯å’Œå®Œæ•´å†…å®¹
_pending_search_sources: list = []
_pending_search_contents: list = []  # å­˜å‚¨å®Œæ•´çš„æœç´¢å†…å®¹ç”¨äºæŠ¥å‘Šç”Ÿæˆ

@tool
def search_flood_event(query: str) -> str:
    """
    æœç´¢æ´ªæ°´äº‹ä»¶çš„ç›¸å…³ä¿¡æ¯ã€‚
    
    Args:
        query: æœç´¢æŸ¥è¯¢ï¼Œåº”åŒ…å«æ´ªæ°´äº‹ä»¶åç§°ã€åœ°ç‚¹ã€æ—¶é—´ç­‰å…³é”®ä¿¡æ¯
        
    Returns:
        æœç´¢ç»“æœçš„æ‘˜è¦æ–‡æœ¬
    """
    global _pending_search_sources, _pending_search_contents
    try:
        from tavily import TavilyClient
        tavily_client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
        
        # ä½¿ç”¨å¤šä¸ªæœç´¢ç­–ç•¥è·å–æ›´å¤šæ¥æº
        all_results = []
        all_sources = []
        seen_urls = set()
        
        # æœç´¢ç­–ç•¥1ï¼šåŸºæœ¬æœç´¢
        enhanced_query = f"{query} flood disaster timeline date"
        response = tavily_client.search(
            query=enhanced_query,
            search_depth="advanced",
            max_results=8,
            include_answer=True
        )
        
        results = []
        if response.get("answer"):
            results.append(f"Summary: {response['answer']}")
        
        for result in response.get("results", []):
            url = result.get("url", "")
            if url and url not in seen_urls:
                seen_urls.add(url)
                title = result.get("title", "")
                content = result.get("content", "")
                results.append(f"Title: {title}\nContent: {content}\nSource: {url}\n")
                if title and url:
                    all_sources.append({"title": title, "url": url, "content": content})
        
        # Search strategy 2: impact and losses
        impact_query = f"{query} impact damage casualties affected"
        try:
            response2 = tavily_client.search(
                query=impact_query,
                search_depth="advanced",
                max_results=5,
                include_answer=False
            )
            for result in response2.get("results", []):
                url = result.get("url", "")
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    title = result.get("title", "")
                    content = result.get("content", "")
                    results.append(f"Title: {title}\nContent: {content}\nSource: {url}\n")
                    if title and url:
                        all_sources.append({"title": title, "url": url, "content": content})
        except:
            pass
        
        # Search strategy 3: emergency response
        rescue_query = f"{query} rescue emergency response evacuation"
        try:
            response3 = tavily_client.search(
                query=rescue_query,
                search_depth="basic",
                max_results=5,
                include_answer=False
            )
            for result in response3.get("results", []):
                url = result.get("url", "")
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    title = result.get("title", "")
                    content = result.get("content", "")
                    results.append(f"Title: {title}\nContent: {content}\nSource: {url}\n")
                    if title and url:
                        all_sources.append({"title": title, "url": url, "content": content})
        except:
            pass
        
        _pending_search_sources = [{"title": s["title"], "url": s["url"]} for s in all_sources]
        _pending_search_contents = all_sources  # Store full content for report generation
        
        print(f"ğŸ“š æœç´¢å®Œæˆï¼Œè·å–åˆ° {len(all_sources)} æ¡ä¿¡æ¯æ¥æº")
        
        return "\n---\n".join(results) if results else "No relevant flood event information found"
        
    except Exception as e:
        _pending_search_sources = []
        _pending_search_contents = []
        return f"Search error: {str(e)}"


# å·¥å…·åˆ—è¡¨
tools = [search_flood_event]


# ============== èŠ‚ç‚¹å®šä¹‰ ==============

# å®šä¹‰èŠ‚ç‚¹è·¯ç”±ç±»å‹
NodeType = Literal["chat_node", "tool_node", "extraction_node", "confirmation_node", "processing_node", "__end__"]


async def entry_node(
    state: FloodAgentState, config: RunnableConfig
) -> Command[NodeType]:
    """
    å…¥å£èŠ‚ç‚¹ - åˆ†æç”¨æˆ·æ„å›¾å¹¶è·¯ç”±
    
    èŒè´£ï¼š
    1. åˆ¤æ–­å½“å‰é˜¶æ®µ
    2. å¦‚æœæ˜¯å·²å®Œæˆé˜¶æ®µä¸”æœ‰æ–°æ¶ˆæ¯ï¼Œé‡ç½®çŠ¶æ€
    3. è·¯ç”±åˆ° chat_node è¿›è¡Œå¤„ç†
    """
    current_stage = state.get('stage', 'initial')
    
    # å¦‚æœå·²å®Œæˆä½†ç”¨æˆ·å‘é€æ–°æ¶ˆæ¯ï¼Œé‡ç½®ä¸ºåˆå§‹çŠ¶æ€
    if current_stage == "completed":
        return Command(
            goto="chat_node",
            update={
                "stage": "initial",
                "user_confirmed": False,
                "event": None,
                "event_description": None,
                "flood_report": None,
            }
        )
    
    return Command(goto="chat_node")


async def chat_node(
    state: FloodAgentState, config: RunnableConfig
) -> Command[NodeType]:
    """
    èŠå¤©èŠ‚ç‚¹ - å¤„ç† LLM å¯¹è¯å’Œå·¥å…·è°ƒç”¨
    
    èŒè´£ï¼š
    1. ä¸ LLM äº¤äº’
    2. å¤„ç†å·¥å…·è°ƒç”¨è¯·æ±‚
    3. è·¯ç”±åˆ° tool_node æˆ– extraction_node
    """
    model = _get_model()
    
    # è·å–å‰ç«¯å·¥å…·å¹¶ç»‘å®šæ‰€æœ‰å·¥å…·
    fe_tools = state.get("copilotkit", {}).get("actions", [])
    model_with_tools = model.bind_tools([*fe_tools, *tools])
    
    # æ„å»ºç³»ç»Ÿæç¤º
    current_stage = state.get('stage', 'initial')
    system_message = SystemMessage(
        content=f"""{SYSTEM_PROMPT}

[Current Stage]: {current_stage}
When a user asks about a flood event, use the search_flood_event tool to search for information.
After searching, append JSON-formatted event information at the end of the response.
"""
    )
    
    # è°ƒç”¨æ¨¡å‹
    response = await model_with_tools.ainvoke(
        [system_message, *state["messages"]],
        config,
    )
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
    tool_calls = response.tool_calls
    
    if tool_calls and _should_route_to_tool_node(tool_calls, fe_tools):
        return Command(
            goto="tool_node", 
            update={"messages": response}
        )
    
    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿›å…¥æå–èŠ‚ç‚¹åˆ†æå“åº”
    return Command(
        goto="extraction_node",
        update={"messages": response}
    )


async def extraction_node(
    state: FloodAgentState, config: RunnableConfig
) -> Command[NodeType]:
    """
    ä¿¡æ¯æå–èŠ‚ç‚¹ - ä» LLM å“åº”ä¸­æå–ç»“æ„åŒ–æ•°æ®
    
    èŒè´£ï¼š
    1. è§£æ LLM å“åº”ä¸­çš„ JSON æ•°æ®
    2. æå–æ´ªæ°´äº‹ä»¶ä¿¡æ¯
    3. åˆ¤æ–­æ˜¯å¦æœ‰å®Œæ•´ä¿¡æ¯éœ€è¦ç¡®è®¤
    """
    # è·å–æœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹
    messages = state.get("messages", [])
    print(f"ğŸ“ æå–èŠ‚ç‚¹å¤„ç†æ¶ˆæ¯ï¼Œå…± {len(messages)} æ¡")
    if not messages:
        return Command(goto="__end__")
    
    last_message = messages[-1]
    content = str(last_message.content) if hasattr(last_message, 'content') else str(last_message)
    
    print(f"ğŸ” æå–èŠ‚ç‚¹åˆ†æå†…å®¹:\n{content}\n")
    # æå–æ´ªæ°´ä¿¡æ¯
    extracted_info = _extract_flood_info_from_content(content)
    
    # åˆå¹¶åˆ°å½“å‰çŠ¶æ€
    event = extracted_info.get("event") or state.get("event")
    event_description = extracted_info.get("event_description") or state.get("event_description")
    location = extracted_info.get("location") or state.get("location")
    pre_date = extracted_info.get("pre_date") or state.get("pre_date")
    peek_date = extracted_info.get("peek_date") or state.get("peek_date")
    after_date = extracted_info.get("after_date") or state.get("after_date")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„æ–°äº‹ä»¶ä¿¡æ¯
    has_complete_info = all([
        extracted_info.get("event"),
        extracted_info.get("pre_date"),
        extracted_info.get("peek_date"),
        extracted_info.get("after_date")
    ])
    
    user_confirmed = state.get('user_confirmed', False)
    current_stage = state.get('stage', 'initial')
    
    # å¦‚æœæœ‰å®Œæ•´ä¿¡æ¯ä¸”æœªç¡®è®¤ï¼Œè¿›å…¥ç¡®è®¤èŠ‚ç‚¹
    if has_complete_info and not user_confirmed and current_stage != "completed":
        return Command(
            goto="confirmation_node",
            update={
                "event": event,
                "event_description": event_description,
                "location": location,
                "pre_date": pre_date,
                "peek_date": peek_date,
                "after_date": after_date,
                "stage": "pending_confirmation",
            }
        )
    
    # æ™®é€šå“åº”ï¼Œç»“æŸæµç¨‹
    return Command(
        goto="__end__",
        update={
            "event": event,
            "event_description": event_description,
            "location": location,
            "pre_date": pre_date,
            "peek_date": peek_date,
            "after_date": after_date,
        }
    )


async def confirmation_node(
    state: FloodAgentState, config: RunnableConfig
) -> Command[NodeType]:
    """
    ç¡®è®¤èŠ‚ç‚¹ - Human-in-the-Loop ç”¨æˆ·ç¡®è®¤
    
    èŒè´£ï¼š
    1. ä½¿ç”¨ interrupt æš‚åœæ‰§è¡Œ
    2. ç­‰å¾…ç”¨æˆ·ç¡®è®¤æˆ–ä¿®æ”¹äº‹ä»¶ä¿¡æ¯
    3. å¤„ç†ç”¨æˆ·å–æ¶ˆæ“ä½œ
    """
    event = state.get("event")
    event_description = state.get("event_description")
    location = state.get("location")
    pre_date = state.get("pre_date")
    peek_date = state.get("peek_date")
    after_date = state.get("after_date")
    
    # ä½¿ç”¨ interrupt æš‚åœæ‰§è¡Œï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤
    confirmed_data_raw = interrupt({
        "type": "confirm_flood_event",
        "message": "Please confirm or modify the following flood event information:",
        "data": {
            "event": event,
            "event_description": event_description,
            "location": location,
            "pre_date": pre_date,
            "peek_date": peek_date,
            "after_date": after_date,
        }
    })
    
    # è§£æç”¨æˆ·ç¡®è®¤æ•°æ®
    confirmed_data = {}
    if isinstance(confirmed_data_raw, str):
        try:
            confirmed_data = json.loads(confirmed_data_raw)
        except json.JSONDecodeError:
            confirmed_data = {}
    elif isinstance(confirmed_data_raw, dict):
        confirmed_data = confirmed_data_raw
    
    # ç”¨æˆ·å–æ¶ˆ
    if not confirmed_data or confirmed_data.get("cancelled"):
        cancel_message = AIMessage(content="Cancelled. If you'd like to query again, please tell me which flood event you'd like to learn about.")
        return Command(
            goto="__end__",
            update={
                "messages": cancel_message,
                "stage": "initial",
                "user_confirmed": False,
            }
        )
    
    # ç”¨æˆ·ç¡®è®¤ï¼Œæ›´æ–°æ•°æ®å¹¶è¿›å…¥å¤„ç†èŠ‚ç‚¹
    print(f"ğŸ“ ç”¨æˆ·å·²ç¡®è®¤äº‹ä»¶ä¿¡æ¯")
    
    return Command(
        goto="processing_node",
        update={
            "event": confirmed_data.get("event", event),
            "event_description": confirmed_data.get("event_description", event_description),
            "location": confirmed_data.get("location", location),
            "pre_date": confirmed_data.get("pre_date", pre_date),
            "peek_date": confirmed_data.get("peek_date", peek_date),
            "after_date": confirmed_data.get("after_date", after_date),
            "stage": "confirmed",
            "user_confirmed": True,
        }
    )


async def processing_node(
    state: FloodAgentState, config: RunnableConfig
) -> Command[NodeType]:
    """
    å¤„ç†èŠ‚ç‚¹ - åœ°ç†ç¼–ç å’ŒæŠ¥å‘Šç”Ÿæˆ
    
    èŒè´£ï¼š
    1. è°ƒç”¨åœ°ç†ç¼–ç  API è·å–åæ ‡
    2. ä½¿ç”¨ LLM åŸºäºæœç´¢å†…å®¹ç”Ÿæˆè¯¦ç»†æ´ªæ°´åˆ†ææŠ¥å‘Š
    3. æ›´æ–°æœ€ç»ˆçŠ¶æ€
    """
    global _pending_search_contents
    
    location = state.get("location")
    event = state.get("event")
    event_description = state.get("event_description")
    pre_date = state.get("pre_date")
    peek_date = state.get("peek_date")
    after_date = state.get("after_date")
    
    print(f"ğŸ“ æ­£åœ¨è·å–åœ°ç†åæ ‡: {location}")
    
    # è·å–åœ°ç†åæ ‡
    geo_data = _get_location_coordinates_internal(location) if location else None
    
    if geo_data:
        coordinates = geo_data.get("coordinates")
        bounds = geo_data.get("bounds")
        geojson = geo_data.get("geojson")
    else:
        coordinates = [105.0, 35.0]
        bounds = {"south": 18.0, "north": 54.0, "west": 73.0, "east": 135.0}
        geojson = None
        geo_data = {}
    
    # æ ¼å¼åŒ–æœç´¢å†…å®¹ç”¨äº LLM ç”ŸæˆæŠ¥å‘Š
    search_contents_text = ""
    if _pending_search_contents:
        for i, item in enumerate(_pending_search_contents, 1):
            title = item.get("title", "")
            content = item.get("content", "")
            url = item.get("url", "")
            search_contents_text += f"### Source {i}: {title}\n{content}\nSource URL: {url}\n\n"
    else:
        search_contents_text = "No search materials available. Please analyze based on the event description."
    
    # ä½¿ç”¨ LLM ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    print(f"ğŸ“ æ­£åœ¨ä½¿ç”¨ LLM ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š...")
    model = _get_model()
    
    report_prompt = REPORT_GENERATION_PROMPT.format(
        event=event or "Unknown event",
        location=location or "To be determined",
        pre_date=pre_date or "To be determined",
        peek_date=peek_date or "To be determined",
        after_date=after_date or "To be determined",
        search_contents=search_contents_text
    )
    
    try:
        response = model.invoke([HumanMessage(content=report_prompt)])
        detailed_report = response.content
        print(f"âœ… LLM ç”ŸæˆæŠ¥å‘ŠæˆåŠŸï¼Œå­—æ•°: {len(detailed_report)}")
    except Exception as e:
        print(f"âš ï¸ LLM ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹")
        detailed_report = f"""### 1. Event Overview
{event_description or 'No detailed description available'}

### 2. Cause Analysis
Limited information available; no specific cause analysis at this time.

### 3. Impact and Loss Assessment
Limited information available; no specific loss data at this time.

### 4. Emergency Response and Rescue Operations
Limited information available; no specific rescue information at this time.

### 5. Post-disaster Recovery and Lessons Learned
Limited information available; no recovery progress information at this time.

### 6. Comprehensive Summary
This flood event has caused certain impacts. Further information collection is needed for a complete assessment."""
    
    # æ ¼å¼åŒ–æ¥æºä¿¡æ¯
    sources_text = _format_sources_text(_pending_search_sources)
    
    # ç»„è£…æœ€ç»ˆæŠ¥å‘Š
    flood_report = FLOOD_REPORT_TEMPLATE.format(
        event=event or "Unknown event",
        pre_date=pre_date or "To be determined",
        peek_date=peek_date or "To be determined",
        after_date=after_date or "To be determined",
        location=location or "To be determined",
        detailed_report=detailed_report,
        sources=sources_text
    )
    
    # ä¿å­˜æ¥æºä¿¡æ¯
    search_sources = _pending_search_sources.copy() if _pending_search_sources else []
    
    # åˆ›å»ºæŠ¥å‘Šå®Œæˆæ¶ˆæ¯
    report_message = AIMessage(content=f"âœ… Information confirmed, report generated!\n\n{flood_report}")
    
    print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œå…± {len(search_sources)} æ¡å‚è€ƒæ¥æº")
    
    return Command(
        goto="__end__",
        update={
            "messages": report_message,
            "event": event,
            "event_description": event_description,
            "flood_report": flood_report,
            "report_document": flood_report,  # åŒæ­¥åˆ°å¯ç¼–è¾‘çš„æ–‡æ¡£
            "pre_date": pre_date,
            "after_date": after_date,
            "peek_date": peek_date,
            "location": location,
            "coordinates": coordinates,
            "bounds": bounds,
            "geojson": geojson,
            "geo_data": geo_data,
            "search_sources": search_sources,
            "stage": "completed",
            "user_confirmed": True,
            "is_valid_flood_query": True,
        }
    )


# ============== æ„å»ºå›¾ ==============

workflow = StateGraph(FloodAgentState)

# æ·»åŠ èŠ‚ç‚¹ - æ¸…æ™°çš„èŒè´£åˆ†ç¦»
workflow.add_node("entry_node", entry_node)           # å…¥å£è·¯ç”±
workflow.add_node("chat_node", chat_node)             # LLM å¯¹è¯ + å·¥å…·è°ƒç”¨
workflow.add_node("tool_node", ToolNode(tools=tools)) # å·¥å…·æ‰§è¡Œ
workflow.add_node("extraction_node", extraction_node) # ä¿¡æ¯æå–
workflow.add_node("confirmation_node", confirmation_node)  # ç”¨æˆ·ç¡®è®¤ (HITL)
workflow.add_node("processing_node", processing_node) # åœ°ç†ç¼–ç  + æŠ¥å‘Šç”Ÿæˆ
# workflow.add_node("__end__", lambda state, config: None)

# è®¾ç½®å…¥å£ç‚¹
workflow.set_entry_point("entry_node")

# æ·»åŠ è¾¹ - å®šä¹‰æµç¨‹
workflow.add_edge("tool_node", "chat_node")  # å·¥å…·æ‰§è¡Œåå›åˆ°èŠå¤©èŠ‚ç‚¹
# ç¼–è¯‘å›¾
checkpointer = MemorySaver()
graph = workflow.compile(checkpointer=checkpointer)


# ============== å›¾ç»“æ„è¯´æ˜ ==============
"""
é‡æ„åçš„å›¾ç»“æ„ (5ä¸ªä¸»è¦èŠ‚ç‚¹):

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   entry_node    â”‚  å…¥å£è·¯ç”±
                    â”‚   (åˆ¤æ–­é˜¶æ®µ)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”Œâ”€â”€â”€â”€â–¶â”‚   chat_node     â”‚â—€â”€â”€â”€â”€â”
              â”‚     â”‚  (LLMå¯¹è¯)       â”‚     â”‚
              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
              â”‚              â”‚              â”‚
              â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
              â”‚    â”‚                   â”‚    â”‚
              â”‚    â–¼                   â–¼    â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   tool_node    â”‚    â”‚ extraction_node â”‚
      â”‚  (å·¥å…·æ‰§è¡Œ)     â”‚    â”‚   (ä¿¡æ¯æå–)    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚                             â”‚
                      â–¼                             â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚confirmation_nodeâ”‚            â”‚    __end__    â”‚
            â”‚   (HITLç¡®è®¤)    â”‚            â”‚   (æ™®é€šç»“æŸ)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                     â”‚
          â–¼                     â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚processing_node  â”‚   â”‚    __end__    â”‚
 â”‚(åœ°ç†ç¼–ç +æŠ¥å‘Š)   â”‚   â”‚   (ç”¨æˆ·å–æ¶ˆ)  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚    __end__    â”‚
 â”‚  (æµç¨‹å®Œæˆ)    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

èŠ‚ç‚¹èŒè´£:
- entry_node: å…¥å£è·¯ç”±ï¼Œåˆ¤æ–­é˜¶æ®µï¼Œå¤„ç†çŠ¶æ€é‡ç½®
- chat_node: LLM å¯¹è¯å¤„ç†ï¼Œå·¥å…·è°ƒç”¨å†³ç­–
- tool_node: æ‰§è¡Œæœç´¢å·¥å…·
- extraction_node: ä» LLM å“åº”æå–ç»“æ„åŒ–æ•°æ®
- confirmation_node: Human-in-the-Loop ç”¨æˆ·ç¡®è®¤
- processing_node: åœ°ç†ç¼–ç  + æŠ¥å‘Šç”Ÿæˆ
"""
