"""
æ´ªæ°´æ™ºèƒ½ä½“ - ä½¿ç”¨ LangGraph æ„å»º
åŸºäº CopilotKit AG-UI åè®®
æ”¯æŒ Human-in-the-Loop (HITL) é€šè¿‡ interrupt å®ç°

é‡æ„ç‰ˆæœ¬ï¼šé‡‡ç”¨æ¸…æ™°çš„èŠ‚ç‚¹åˆ†ç¦»è®¾è®¡
- entry_node: å…¥å£è·¯ç”±ï¼Œåˆ¤æ–­ç”¨æˆ·æ„å›¾
- chat_node: é€šç”¨èŠå¤©ï¼Œå¤„ç†å·¥å…·è°ƒç”¨
- extraction_node: ä¿¡æ¯æå–ï¼Œä»æœç´¢ç»“æœæå–ç»“æ„åŒ–æ•°æ®
- confirmation_node: ç”¨æˆ·ç¡®è®¤ (HITL)
- processing_node: æ•°æ®å¤„ç†ï¼Œåœ°ç†ç¼–ç  + æŠ¥å‘Šç”Ÿæˆ
"""
import os
import json
import requests
from typing import Literal, Optional, Dict, Any

from dotenv import load_dotenv
from langchain.tools import tool
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, AIMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, interrupt

from state import FloodAgentState
from prompts import SYSTEM_PROMPT, FLOOD_REPORT_TEMPLATE, REPORT_GENERATION_PROMPT

load_dotenv()

# é…ç½®ä»£ç†
http_proxy = os.getenv("HTTP_PROXY")
https_proxy = os.getenv("HTTPS_PROXY")
if http_proxy:
    os.environ["HTTP_PROXY"] = http_proxy
if https_proxy:
    os.environ["HTTPS_PROXY"] = https_proxy


# ============== å†…éƒ¨å‡½æ•° ==============

def _classify_location_type(location_name: str) -> dict:
    """
    ä½¿ç”¨LLMåˆ¤æ–­åœ°åç±»å‹
    
    è¿”å›:
    - type: "administrative" (è¡Œæ”¿åŒºåŸŸ) æˆ– "composite" (ç»„åˆ/è‡ªç„¶åŒºåŸŸ)
    - reason: åˆ¤æ–­åŸå› 
    """
    try:
        model = _get_model()
        
        prompt = f"""è¯·åˆ¤æ–­ä»¥ä¸‹åœ°åçš„ç±»å‹ï¼š

åœ°å: {location_name}

åˆ¤æ–­æ ‡å‡†:
1. "administrative" - ç‹¬ç«‹çš„è¡Œæ”¿åŒºåŸŸï¼Œå¦‚ï¼šå›½å®¶ã€çœ/å·ã€å¸‚ã€å¿ã€åŒºç­‰æœ‰æ˜ç¡®è¡Œæ”¿è¾¹ç•Œçš„åœ°åŒº
   ä¾‹å¦‚ï¼šåŒ—äº¬å¸‚ã€å¾·å›½ã€åŠ åˆ©ç¦å°¼äºšå·ã€ä¸œäº¬éƒ½ã€å·´é»

2. "composite" - ç»„åˆåœ°åã€åœ°ç†åŒºä½æˆ–è‡ªç„¶åŒºåŸŸï¼ŒåŒ…æ‹¬ï¼š
   - å¤šä¸ªè¡Œæ”¿åŒºåŸŸçš„ç»„åˆï¼šäº¬æ´¥å†€ã€é•¿ä¸‰è§’ã€ç ä¸‰è§’ã€æ¬§ç›Ÿ
   - åœ°ç†åŒºä½æ¦‚å¿µï¼šååŒ—åœ°åŒºã€ä¸œå—äºšã€ä¸­ä¸œ
   - è‡ªç„¶åœ°ç†åŒºåŸŸï¼šé»„æ²³æµåŸŸã€äºšé©¬é€Šç›†åœ°ã€é˜¿å°”å‘æ–¯å±±åŒº
   - è·¨è¡Œæ”¿åŒºåŸŸçš„åœ°ç†å•å…ƒï¼šå¯†è¥¿è¥¿æ¯”æ²³æµåŸŸã€å¤šç‘™æ²³å¹³åŸ

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ï¼š
```json
{{"type": "administrativeæˆ–composite", "reason": "ç®€çŸ­è¯´æ˜"}}
```"""

        response = model.invoke([HumanMessage(content=prompt)])
        content = response.content
        
        # æå–JSON
        if "```json" in content:
            json_str = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            json_str = content.split("```")[1].split("```")[0]
        else:
            json_str = content
        
        data = json.loads(json_str.strip())
        location_type = data.get("type", "administrative")
        reason = data.get("reason", "")
        
        print(f"ğŸ” åœ°åç±»å‹åˆ¤æ–­: {location_name} -> {location_type} ({reason})")
        return {"type": location_type, "reason": reason}
        
    except Exception as e:
        print(f"âš ï¸ LLMåˆ¤æ–­åœ°åç±»å‹å¤±è´¥: {e}ï¼Œé»˜è®¤ä¸ºè¡Œæ”¿åŒºåŸŸ")
        return {"type": "administrative", "reason": "åˆ¤æ–­å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼"}


def _generate_geojson_with_llm(location_name: str) -> Optional[Dict[str, Any]]:
    """
    ä½¿ç”¨LLMç”Ÿæˆç»„åˆåŒºåŸŸçš„å¤§è‡´GeoJSONè¾¹ç•Œ
    é€‚ç”¨äºï¼šç»„åˆåœ°åã€åœ°ç†åŒºä½ã€è‡ªç„¶åŒºåŸŸç­‰éæ ‡å‡†è¡Œæ”¿åŒºåŸŸ
    """
    try:
        model = _get_model()
        
        prompt = f"""è¯·ä¸ºä»¥ä¸‹åœ°ç†åŒºåŸŸç”Ÿæˆä¸€ä¸ªå¤§è‡´çš„GeoJSONè¾¹ç•Œæ•°æ®ã€‚

åœ°ç†åŒºåŸŸåç§°: {location_name}

è¦æ±‚:
1. ç”Ÿæˆä¸€ä¸ªç®€åŒ–çš„å¤šè¾¹å½¢(Polygon)è¾¹ç•Œï¼Œç”¨4-8ä¸ªé¡¶ç‚¹å³å¯è¡¨ç¤ºå¤§è‡´èŒƒå›´
2. åæ ‡æ ¼å¼ä¸º [ç»åº¦, çº¬åº¦]ï¼Œä½¿ç”¨WGS84åæ ‡ç³»
3. å¤šè¾¹å½¢å¿…é¡»é—­åˆï¼ˆé¦–å°¾åæ ‡ç›¸åŒï¼‰
4. åŒæ—¶æä¾›ä¸­å¿ƒç‚¹åæ ‡å’Œè¾¹ç•Œæ¡†

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š

```json
{{
    "center": [ç»åº¦, çº¬åº¦],
    "bounds": {{
        "west": æœ€è¥¿ç»åº¦,
        "south": æœ€å—çº¬åº¦,
        "east": æœ€ä¸œç»åº¦,
        "north": æœ€åŒ—çº¬åº¦
    }},
    "geometry": {{
        "type": "Polygon",
        "coordinates": [[[ç»åº¦1, çº¬åº¦1], [ç»åº¦2, çº¬åº¦2], ..., [ç»åº¦1, çº¬åº¦1]]]
    }}
}}
```"""

        response = model.invoke([HumanMessage(content=prompt)])
        content = response.content
        
        # æå–JSON
        if "```json" in content:
            json_str = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            json_str = content.split("```")[1].split("```")[0]
        else:
            json_str = content
        
        data = json.loads(json_str.strip())
        
        # éªŒè¯æ•°æ®ç»“æ„
        if not all(k in data for k in ['center', 'bounds', 'geometry']):
            raise ValueError("ç¼ºå°‘å¿…è¦å­—æ®µ")
        
        # æ„å»ºGeoJSON Feature
        geojson_feature = {
            'type': 'Feature',
            'properties': {
                'name': location_name,
                'type': 'composite_region',
                'source': 'LLM_generated'
            },
            'geometry': data['geometry']
        }
        
        print(f"âœ… LLMæˆåŠŸç”Ÿæˆåœ°ç†æ•°æ®: {location_name}")
        return {
            "location": location_name,
            "coordinates": data['center'],
            "bounds": data['bounds'],
            "geojson": geojson_feature,
            "type": "composite_region",
            "source": "LLM_generated"
        }
        
    except Exception as e:
        print(f"âŒ LLMç”ŸæˆGeoJSONå¤±è´¥: {e}")
        return None


def _get_location_from_nominatim(location_name: str) -> Optional[Dict[str, Any]]:
    """
    ä»Nominatim APIè·å–è¡Œæ”¿åŒºåŸŸçš„GeoJSON
    ä¸é™åˆ¶å›½å®¶èŒƒå›´
    """
    try:
        import time
        time.sleep(1)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        
        nominatim_url = "https://nominatim.openstreetmap.org/search"
        params = {
            'q': location_name,
            'format': 'geojson',
            'polygon_geojson': 1,
            'limit': 1,
            'accept-language': 'zh-CN,en'  # ä¼˜å…ˆä¸­æ–‡ï¼Œå…¶æ¬¡è‹±æ–‡
        }
        
        headers = {
            'User-Agent': 'FloodAgent/1.0 (flood monitoring application)'
        }
        
        response = requests.get(nominatim_url, params=params, headers=headers, timeout=15)
        response.raise_for_status()
        
        data = response.json()
        
        if not data.get('features'):
            return None
        
        feature = data['features'][0]
        geometry = feature.get('geometry')
        properties = feature.get('properties', {})
        
        # è®¡ç®—è¾¹ç•Œæ¡†å’Œä¸­å¿ƒç‚¹
        bounds = None
        center = None
        
        if geometry and geometry.get('coordinates'):
            if geometry['type'] == 'Point':
                lon, lat = geometry['coordinates']
                buffer = 0.5  # å¯¹äºç‚¹ï¼Œåˆ›å»ºè¾ƒå¤§çš„ç¼“å†²åŒº
                bounds = {
                    'west': lon - buffer,
                    'south': lat - buffer,
                    'east': lon + buffer,
                    'north': lat + buffer
                }
                center = [lon, lat]
            else:
                def extract_coords(coords, result_coords=None):
                    if result_coords is None:
                        result_coords = []
                    if isinstance(coords[0], (int, float)):
                        result_coords.append(coords)
                    else:
                        for coord in coords:
                            extract_coords(coord, result_coords)
                    return result_coords
                
                all_coords = extract_coords(geometry['coordinates'])
                if all_coords:
                    lons = [coord[0] for coord in all_coords]
                    lats = [coord[1] for coord in all_coords]
                    bounds = {
                        'west': min(lons),
                        'south': min(lats),
                        'east': max(lons),
                        'north': max(lats)
                    }
                    center = [
                        (bounds['west'] + bounds['east']) / 2,
                        (bounds['south'] + bounds['north']) / 2
                    ]
        
        geojson_feature = {
            'type': 'Feature',
            'properties': {
                'name': properties.get('display_name', location_name),
                'type': properties.get('type'),
                'class': properties.get('class')
            },
            'geometry': geometry
        }
        
        return {
            "location": properties.get('display_name', location_name),
            "coordinates": center if center else [0.0, 0.0],
            "bounds": bounds if bounds else {"south": -90, "north": 90, "west": -180, "east": 180},
            "geojson": geojson_feature,
            "type": properties.get('type', 'administrative'),
            "source": "Nominatim/OpenStreetMap"
        }
        
    except Exception as e:
        print(f"âš ï¸ NominatimæŸ¥è¯¢å¤±è´¥: {e}")
        return None


def _get_location_coordinates_internal(location_name: str) -> Optional[Dict[str, Any]]:
    """
    æ™ºèƒ½åœ°ç†ç¼–ç å‡½æ•°
    
    ç­–ç•¥ï¼š
    1. ä½¿ç”¨LLMåˆ¤æ–­åœ°åç±»å‹ï¼ˆè¡Œæ”¿åŒºåŸŸ vs ç»„åˆ/è‡ªç„¶åŒºåŸŸï¼‰
    2. è¡Œæ”¿åŒºåŸŸ â†’ ä½¿ç”¨Nominatim APIè·å–ç²¾ç¡®GeoJSON
    3. ç»„åˆ/è‡ªç„¶åŒºåŸŸ â†’ ä½¿ç”¨LLMç”Ÿæˆå¤§è‡´GeoJSON
    4. å¦‚æœNominatimå¤±è´¥ï¼Œå›é€€åˆ°LLMç”Ÿæˆ
    """
    print(f"ğŸ“ æ­£åœ¨è·å–åœ°ç†æ•°æ®: {location_name}")
    
    # ä½¿ç”¨LLMåˆ¤æ–­åœ°åç±»å‹
    classification = _classify_location_type(location_name)
    is_composite = classification["type"] == "composite"
    
    if is_composite:
        print(f"ğŸ” æ£€æµ‹åˆ°ç»„åˆåŒºåŸŸï¼Œä½¿ç”¨LLMç”ŸæˆGeoJSON: {location_name}")
        result = _generate_geojson_with_llm(location_name)
        if result:
            return result
        # LLMå¤±è´¥æ—¶å°è¯•Nominatim
        print(f"âš ï¸ LLMç”Ÿæˆå¤±è´¥ï¼Œå°è¯•Nominatim...")
    
    # å°è¯•Nominatim API
    print(f"ğŸŒ å°è¯•ä»Nominatimè·å–: {location_name}")
    result = _get_location_from_nominatim(location_name)
    
    if result:
        print(f"âœ… æˆåŠŸè·å–åœ°ç†æ•°æ®: {location_name}")
        return result
    
    # Nominatimå¤±è´¥ï¼Œå°è¯•LLM
    if not is_composite:
        print(f"âš ï¸ Nominatimæœªæ‰¾åˆ°ï¼Œå°è¯•LLMç”Ÿæˆ: {location_name}")
        result = _generate_geojson_with_llm(location_name)
        if result:
            return result
    
    # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
    print(f"âŒ æ— æ³•è·å–åœ°ç†æ•°æ®: {location_name}")
    return {
        "location": location_name,
        "coordinates": [0.0, 0.0],
        "bounds": {"south": -90, "north": 90, "west": -180, "east": 180},
        "geojson": None,
        "error": f"æ— æ³•è·å– '{location_name}' çš„åœ°ç†ä¿¡æ¯"
    }


def _get_model() -> ChatOpenAI:
    """è·å– LLM æ¨¡å‹å®ä¾‹"""
    return ChatOpenAI(
        model=os.getenv("LLM_MODEL", "gpt-4o-mini"),
        api_key=os.getenv("OPENAI_API_KEY", ""),
        base_url=os.getenv("OPENAI_API_BASE"),
        temperature=0.7
    )


def _should_route_to_tool_node(tool_calls, fe_tools) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·¯ç”±åˆ°å·¥å…·èŠ‚ç‚¹"""
    if not tool_calls:
        return False
    
    fe_tool_names = {tool.get("name") for tool in fe_tools}
    
    for tool_call in tool_calls:
        tool_name = (
            tool_call.get("name")
            if isinstance(tool_call, dict)
            else getattr(tool_call, "name", None)
        )
        if tool_name in fe_tool_names:
            return False
    
    return True


def _extract_flood_info_from_content(content: str) -> dict:
    """ä» LLM å“åº”å†…å®¹ä¸­æå–æ´ªæ°´ä¿¡æ¯"""
    updates = {}
    try:
        if "```json" in content:
            json_str = content.split("```json")[1].split("```")[0]
            data = json.loads(json_str.strip())
            
            field_names = ["event", "event_description", "location", 
                          "pre_date", "peek_date", "after_date", "stage"]
            for field in field_names:
                if data.get(field):
                    updates[field] = data[field]
            
            # æå–åæ ‡å’Œè¾¹ç•Œ
            if data.get("coordinates") and isinstance(data["coordinates"], list) and len(data["coordinates"]) == 2:
                updates["coordinates"] = data["coordinates"]
            if data.get("bounds") and isinstance(data["bounds"], dict):
                required_keys = ["west", "east", "south", "north"]
                if all(k in data["bounds"] for k in required_keys):
                    updates["bounds"] = data["bounds"]
    except (json.JSONDecodeError, IndexError, KeyError):
        pass
    
    return updates


def _format_sources_text(sources: list) -> str:
    """æ ¼å¼åŒ–æ¥æºä¿¡æ¯ä¸º Markdown æ–‡æœ¬"""
    if not sources:
        return "*æœ¬æŠ¥å‘Šä¿¡æ¯ç»¼åˆè‡ªç½‘ç»œå…¬å¼€èµ„æ–™*"
    
    lines = []
    # æ˜¾ç¤ºæ‰€æœ‰æ¥æº
    for i, source in enumerate(sources, 1):
        title = source.get("title", "æœªçŸ¥æ¥æº")
        url = source.get("url", "#")
        lines.append(f"{i}. [{title}]({url})")
    
    result = "\n".join(lines) if lines else "*æœ¬æŠ¥å‘Šä¿¡æ¯ç»¼åˆè‡ªç½‘ç»œå…¬å¼€èµ„æ–™*"
    
    # å¦‚æœæ¥æºä¸è¶³10æ¡ï¼Œæ·»åŠ è¯´æ˜
    if len(sources) < 10:
        result = f"**è¯´æ˜**: ç”±äºè¯¥æ´ªæ°´äº‹ä»¶å…¬å¼€æŠ¥é“æ•°é‡æœ‰é™ï¼Œæœ¬æ¬¡äº‹ä»¶ç›¸å…³ä¿¡æ¯æºè¾ƒå°‘ï¼ˆå…± {len(sources)} æ¡ï¼‰ï¼Œä»¥ä¸‹åˆ†æåŸºäºç°æœ‰å¯è·å–çš„æƒå¨èµ„æ–™è¿›è¡Œæ•´ç†ã€‚\n\n" + result
    
    return result


def _has_complete_flood_info(state: FloodAgentState) -> bool:
    """æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„æ´ªæ°´äº‹ä»¶ä¿¡æ¯"""
    return all([
        state.get("event"),
        state.get("pre_date"),
        state.get("peek_date"),
        state.get("after_date"),
        state.get("location")
    ])


# ============== å·¥å…·å®šä¹‰ ==============

# å…¨å±€å˜é‡ç”¨äºä¸´æ—¶å­˜å‚¨æœç´¢æ¥æºä¿¡æ¯å’Œå®Œæ•´å†…å®¹
_pending_search_sources: list = []
_pending_search_contents: list = []  # å­˜å‚¨å®Œæ•´çš„æœç´¢å†…å®¹ç”¨äºæŠ¥å‘Šç”Ÿæˆ

@tool
def search_flood_event(query: str) -> str:
    """
    æœç´¢æ´ªæ°´äº‹ä»¶çš„ç›¸å…³ä¿¡æ¯ã€‚
    
    Args:
        query: æœç´¢æŸ¥è¯¢ï¼Œåº”åŒ…å«æ´ªæ°´äº‹ä»¶åç§°ã€åœ°ç‚¹ã€æ—¶é—´ç­‰å…³é”®ä¿¡æ¯
        
    Returns:
        æœç´¢ç»“æœçš„æ‘˜è¦æ–‡æœ¬
    """
    global _pending_search_sources, _pending_search_contents
    try:
        from tavily import TavilyClient
        tavily_client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
        
        # ä½¿ç”¨å¤šä¸ªæœç´¢ç­–ç•¥è·å–æ›´å¤šæ¥æº
        all_results = []
        all_sources = []
        seen_urls = set()
        
        # æœç´¢ç­–ç•¥1ï¼šåŸºæœ¬æœç´¢
        enhanced_query = f"{query} æ´ªæ°´ ç¾å®³ æ—¶é—´ æ—¥æœŸ"
        response = tavily_client.search(
            query=enhanced_query,
            search_depth="advanced",
            max_results=8,
            include_answer=True
        )
        
        results = []
        if response.get("answer"):
            results.append(f"ç»¼åˆç­”æ¡ˆ: {response['answer']}")
        
        for result in response.get("results", []):
            url = result.get("url", "")
            if url and url not in seen_urls:
                seen_urls.add(url)
                title = result.get("title", "")
                content = result.get("content", "")
                results.append(f"æ ‡é¢˜: {title}\nå†…å®¹: {content}\næ¥æº: {url}\n")
                if title and url:
                    all_sources.append({"title": title, "url": url, "content": content})
        
        # æœç´¢ç­–ç•¥2ï¼šæœç´¢å½±å“å’ŒæŸå¤±
        impact_query = f"{query} å½±å“ æŸå¤± ä¼¤äº¡ å—ç¾"
        try:
            response2 = tavily_client.search(
                query=impact_query,
                search_depth="advanced",
                max_results=5,
                include_answer=False
            )
            for result in response2.get("results", []):
                url = result.get("url", "")
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    title = result.get("title", "")
                    content = result.get("content", "")
                    results.append(f"æ ‡é¢˜: {title}\nå†…å®¹: {content}\næ¥æº: {url}\n")
                    if title and url:
                        all_sources.append({"title": title, "url": url, "content": content})
        except:
            pass
        
        # æœç´¢ç­–ç•¥3ï¼šæœç´¢åº”æ€¥å“åº”
        rescue_query = f"{query} æ•‘æ´ åº”æ€¥ å“åº” è½¬ç§»"
        try:
            response3 = tavily_client.search(
                query=rescue_query,
                search_depth="basic",
                max_results=5,
                include_answer=False
            )
            for result in response3.get("results", []):
                url = result.get("url", "")
                if url and url not in seen_urls:
                    seen_urls.add(url)
                    title = result.get("title", "")
                    content = result.get("content", "")
                    results.append(f"æ ‡é¢˜: {title}\nå†…å®¹: {content}\næ¥æº: {url}\n")
                    if title and url:
                        all_sources.append({"title": title, "url": url, "content": content})
        except:
            pass
        
        _pending_search_sources = [{"title": s["title"], "url": s["url"]} for s in all_sources]
        _pending_search_contents = all_sources  # å­˜å‚¨å®Œæ•´å†…å®¹ç”¨äºæŠ¥å‘Šç”Ÿæˆ
        
        print(f"ğŸ“š æœç´¢å®Œæˆï¼Œè·å–åˆ° {len(all_sources)} æ¡ä¿¡æ¯æ¥æº")
        
        return "\n---\n".join(results) if results else "æœªæ‰¾åˆ°ç›¸å…³æ´ªæ°´äº‹ä»¶ä¿¡æ¯"
        
    except Exception as e:
        _pending_search_sources = []
        _pending_search_contents = []
        return f"æœç´¢å‡ºé”™: {str(e)}"


# å·¥å…·åˆ—è¡¨
tools = [search_flood_event]


# ============== èŠ‚ç‚¹å®šä¹‰ ==============

# å®šä¹‰èŠ‚ç‚¹è·¯ç”±ç±»å‹
NodeType = Literal["chat_node", "tool_node", "extraction_node", "confirmation_node", "processing_node", "__end__"]


async def entry_node(
    state: FloodAgentState, config: RunnableConfig
) -> Command[NodeType]:
    """
    å…¥å£èŠ‚ç‚¹ - åˆ†æç”¨æˆ·æ„å›¾å¹¶è·¯ç”±
    
    èŒè´£ï¼š
    1. åˆ¤æ–­å½“å‰é˜¶æ®µ
    2. å¦‚æœæ˜¯å·²å®Œæˆé˜¶æ®µä¸”æœ‰æ–°æ¶ˆæ¯ï¼Œé‡ç½®çŠ¶æ€
    3. è·¯ç”±åˆ° chat_node è¿›è¡Œå¤„ç†
    """
    current_stage = state.get('stage', 'initial')
    
    # å¦‚æœå·²å®Œæˆä½†ç”¨æˆ·å‘é€æ–°æ¶ˆæ¯ï¼Œé‡ç½®ä¸ºåˆå§‹çŠ¶æ€
    if current_stage == "completed":
        return Command(
            goto="chat_node",
            update={
                "stage": "initial",
                "user_confirmed": False,
                "event": None,
                "event_description": None,
                "flood_report": None,
            }
        )
    
    return Command(goto="chat_node")


async def chat_node(
    state: FloodAgentState, config: RunnableConfig
) -> Command[NodeType]:
    """
    èŠå¤©èŠ‚ç‚¹ - å¤„ç† LLM å¯¹è¯å’Œå·¥å…·è°ƒç”¨
    
    èŒè´£ï¼š
    1. ä¸ LLM äº¤äº’
    2. å¤„ç†å·¥å…·è°ƒç”¨è¯·æ±‚
    3. è·¯ç”±åˆ° tool_node æˆ– extraction_node
    """
    model = _get_model()
    
    # è·å–å‰ç«¯å·¥å…·å¹¶ç»‘å®šæ‰€æœ‰å·¥å…·
    fe_tools = state.get("copilotkit", {}).get("actions", [])
    model_with_tools = model.bind_tools([*fe_tools, *tools])
    
    # æ„å»ºç³»ç»Ÿæç¤º
    current_stage = state.get('stage', 'initial')
    system_message = SystemMessage(
        content=f"""{SYSTEM_PROMPT}

ã€å½“å‰é˜¶æ®µã€‘: {current_stage}
ç”¨æˆ·è¯¢é—®æ´ªæ°´äº‹ä»¶æ—¶ï¼Œä½¿ç”¨ search_flood_event å·¥å…·æœç´¢ä¿¡æ¯ã€‚
æœç´¢ååœ¨å›å¤æœ«å°¾é™„åŠ  JSON æ ¼å¼çš„äº‹ä»¶ä¿¡æ¯ã€‚
"""
    )
    
    # è°ƒç”¨æ¨¡å‹
    response = await model_with_tools.ainvoke(
        [system_message, *state["messages"]],
        config,
    )
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
    tool_calls = response.tool_calls
    
    if tool_calls and _should_route_to_tool_node(tool_calls, fe_tools):
        return Command(
            goto="tool_node", 
            update={"messages": response}
        )
    
    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿›å…¥æå–èŠ‚ç‚¹åˆ†æå“åº”
    return Command(
        goto="extraction_node",
        update={"messages": response}
    )


async def extraction_node(
    state: FloodAgentState, config: RunnableConfig
) -> Command[NodeType]:
    """
    ä¿¡æ¯æå–èŠ‚ç‚¹ - ä» LLM å“åº”ä¸­æå–ç»“æ„åŒ–æ•°æ®
    
    èŒè´£ï¼š
    1. è§£æ LLM å“åº”ä¸­çš„ JSON æ•°æ®
    2. æå–æ´ªæ°´äº‹ä»¶ä¿¡æ¯
    3. åˆ¤æ–­æ˜¯å¦æœ‰å®Œæ•´ä¿¡æ¯éœ€è¦ç¡®è®¤
    """
    # è·å–æœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹
    messages = state.get("messages", [])
    print(f"ğŸ“ æå–èŠ‚ç‚¹å¤„ç†æ¶ˆæ¯ï¼Œå…± {len(messages)} æ¡")
    if not messages:
        return Command(goto="__end__")
    
    last_message = messages[-1]
    content = str(last_message.content) if hasattr(last_message, 'content') else str(last_message)
    
    print(f"ğŸ” æå–èŠ‚ç‚¹åˆ†æå†…å®¹:\n{content}\n")
    # æå–æ´ªæ°´ä¿¡æ¯
    extracted_info = _extract_flood_info_from_content(content)
    
    # åˆå¹¶åˆ°å½“å‰çŠ¶æ€
    event = extracted_info.get("event") or state.get("event")
    event_description = extracted_info.get("event_description") or state.get("event_description")
    location = extracted_info.get("location") or state.get("location")
    pre_date = extracted_info.get("pre_date") or state.get("pre_date")
    peek_date = extracted_info.get("peek_date") or state.get("peek_date")
    after_date = extracted_info.get("after_date") or state.get("after_date")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„æ–°äº‹ä»¶ä¿¡æ¯
    has_complete_info = all([
        extracted_info.get("event"),
        extracted_info.get("pre_date"),
        extracted_info.get("peek_date"),
        extracted_info.get("after_date")
    ])
    
    user_confirmed = state.get('user_confirmed', False)
    current_stage = state.get('stage', 'initial')
    
    # å¦‚æœæœ‰å®Œæ•´ä¿¡æ¯ä¸”æœªç¡®è®¤ï¼Œè¿›å…¥ç¡®è®¤èŠ‚ç‚¹
    if has_complete_info and not user_confirmed and current_stage != "completed":
        return Command(
            goto="confirmation_node",
            update={
                "event": event,
                "event_description": event_description,
                "location": location,
                "pre_date": pre_date,
                "peek_date": peek_date,
                "after_date": after_date,
                "stage": "pending_confirmation",
            }
        )
    
    # æ™®é€šå“åº”ï¼Œç»“æŸæµç¨‹
    return Command(
        goto="__end__",
        update={
            "event": event,
            "event_description": event_description,
            "location": location,
            "pre_date": pre_date,
            "peek_date": peek_date,
            "after_date": after_date,
        }
    )


async def confirmation_node(
    state: FloodAgentState, config: RunnableConfig
) -> Command[NodeType]:
    """
    ç¡®è®¤èŠ‚ç‚¹ - Human-in-the-Loop ç”¨æˆ·ç¡®è®¤
    
    èŒè´£ï¼š
    1. ä½¿ç”¨ interrupt æš‚åœæ‰§è¡Œ
    2. ç­‰å¾…ç”¨æˆ·ç¡®è®¤æˆ–ä¿®æ”¹äº‹ä»¶ä¿¡æ¯
    3. å¤„ç†ç”¨æˆ·å–æ¶ˆæ“ä½œ
    """
    event = state.get("event")
    event_description = state.get("event_description")
    location = state.get("location")
    pre_date = state.get("pre_date")
    peek_date = state.get("peek_date")
    after_date = state.get("after_date")
    
    # ä½¿ç”¨ interrupt æš‚åœæ‰§è¡Œï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤
    confirmed_data_raw = interrupt({
        "type": "confirm_flood_event",
        "message": "è¯·ç¡®è®¤æˆ–ä¿®æ”¹ä»¥ä¸‹æ´ªæ°´äº‹ä»¶ä¿¡æ¯ï¼š",
        "data": {
            "event": event,
            "event_description": event_description,
            "location": location,
            "pre_date": pre_date,
            "peek_date": peek_date,
            "after_date": after_date,
        }
    })
    
    # è§£æç”¨æˆ·ç¡®è®¤æ•°æ®
    confirmed_data = {}
    if isinstance(confirmed_data_raw, str):
        try:
            confirmed_data = json.loads(confirmed_data_raw)
        except json.JSONDecodeError:
            confirmed_data = {}
    elif isinstance(confirmed_data_raw, dict):
        confirmed_data = confirmed_data_raw
    
    # ç”¨æˆ·å–æ¶ˆ
    if not confirmed_data or confirmed_data.get("cancelled"):
        cancel_message = AIMessage(content="å·²å–æ¶ˆã€‚å¦‚éœ€é‡æ–°æŸ¥è¯¢ï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³äº†è§£çš„æ´ªæ°´äº‹ä»¶ã€‚")
        return Command(
            goto="__end__",
            update={
                "messages": cancel_message,
                "stage": "initial",
                "user_confirmed": False,
            }
        )
    
    # ç”¨æˆ·ç¡®è®¤ï¼Œæ›´æ–°æ•°æ®å¹¶è¿›å…¥å¤„ç†èŠ‚ç‚¹
    print(f"ğŸ“ ç”¨æˆ·å·²ç¡®è®¤äº‹ä»¶ä¿¡æ¯")
    
    return Command(
        goto="processing_node",
        update={
            "event": confirmed_data.get("event", event),
            "event_description": confirmed_data.get("event_description", event_description),
            "location": confirmed_data.get("location", location),
            "pre_date": confirmed_data.get("pre_date", pre_date),
            "peek_date": confirmed_data.get("peek_date", peek_date),
            "after_date": confirmed_data.get("after_date", after_date),
            "stage": "confirmed",
            "user_confirmed": True,
        }
    )


async def processing_node(
    state: FloodAgentState, config: RunnableConfig
) -> Command[NodeType]:
    """
    å¤„ç†èŠ‚ç‚¹ - åœ°ç†ç¼–ç å’ŒæŠ¥å‘Šç”Ÿæˆ
    
    èŒè´£ï¼š
    1. è°ƒç”¨åœ°ç†ç¼–ç  API è·å–åæ ‡
    2. ä½¿ç”¨ LLM åŸºäºæœç´¢å†…å®¹ç”Ÿæˆè¯¦ç»†æ´ªæ°´åˆ†ææŠ¥å‘Š
    3. æ›´æ–°æœ€ç»ˆçŠ¶æ€
    """
    global _pending_search_contents
    
    location = state.get("location")
    event = state.get("event")
    event_description = state.get("event_description")
    pre_date = state.get("pre_date")
    peek_date = state.get("peek_date")
    after_date = state.get("after_date")
    
    print(f"ğŸ“ æ­£åœ¨è·å–åœ°ç†åæ ‡: {location}")
    
    # è·å–åœ°ç†åæ ‡
    geo_data = _get_location_coordinates_internal(location) if location else None
    
    if geo_data:
        coordinates = geo_data.get("coordinates")
        bounds = geo_data.get("bounds")
        geojson = geo_data.get("geojson")
    else:
        coordinates = [105.0, 35.0]
        bounds = {"south": 18.0, "north": 54.0, "west": 73.0, "east": 135.0}
        geojson = None
        geo_data = {}
    
    # æ ¼å¼åŒ–æœç´¢å†…å®¹ç”¨äº LLM ç”ŸæˆæŠ¥å‘Š
    search_contents_text = ""
    if _pending_search_contents:
        for i, item in enumerate(_pending_search_contents, 1):
            title = item.get("title", "")
            content = item.get("content", "")
            url = item.get("url", "")
            search_contents_text += f"### æ¥æº {i}: {title}\n{content}\næ¥æºé“¾æ¥: {url}\n\n"
    else:
        search_contents_text = "æš‚æ— æœç´¢èµ„æ–™ï¼Œè¯·åŸºäºäº‹ä»¶æè¿°è¿›è¡Œåˆ†æã€‚"
    
    # ä½¿ç”¨ LLM ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    print(f"ğŸ“ æ­£åœ¨ä½¿ç”¨ LLM ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š...")
    model = _get_model()
    
    report_prompt = REPORT_GENERATION_PROMPT.format(
        event=event or "æœªçŸ¥äº‹ä»¶",
        location=location or "å¾…ç¡®å®š",
        pre_date=pre_date or "å¾…ç¡®å®š",
        peek_date=peek_date or "å¾…ç¡®å®š",
        after_date=after_date or "å¾…ç¡®å®š",
        search_contents=search_contents_text
    )
    
    try:
        response = model.invoke([HumanMessage(content=report_prompt)])
        detailed_report = response.content
        print(f"âœ… LLM ç”ŸæˆæŠ¥å‘ŠæˆåŠŸï¼Œå­—æ•°: {len(detailed_report)}")
    except Exception as e:
        print(f"âš ï¸ LLM ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹")
        detailed_report = f"""### 1. äº‹ä»¶æ¦‚è¿°
{event_description or 'æš‚æ— è¯¦ç»†æè¿°'}

### 2. æˆå› åˆ†æ
ç›¸å…³èµ„æ–™æœ‰é™ï¼Œæš‚æ— å…·ä½“æˆå› åˆ†æã€‚

### 3. å½±å“ä¸æŸå¤±è¯„ä¼°
ç›¸å…³èµ„æ–™æœ‰é™ï¼Œæš‚æ— å…·ä½“æŸå¤±æ•°æ®ã€‚

### 4. åº”æ€¥å“åº”ä¸æ•‘æ´è¡ŒåŠ¨
ç›¸å…³èµ„æ–™æœ‰é™ï¼Œæš‚æ— å…·ä½“æ•‘æ´ä¿¡æ¯ã€‚

### 5. ç¾åæ¢å¤ä¸é—®é¢˜åæ€
ç›¸å…³èµ„æ–™æœ‰é™ï¼Œæš‚æ— æ¢å¤è¿›å±•ä¿¡æ¯ã€‚

### 6. ç»¼åˆæ€»ç»“
æœ¬æ¬¡æ´ªæ°´äº‹ä»¶é€ æˆäº†ä¸€å®šå½±å“ï¼Œå…·ä½“æƒ…å†µæœ‰å¾…è¿›ä¸€æ­¥ä¿¡æ¯æ”¶é›†ã€‚"""
    
    # æ ¼å¼åŒ–æ¥æºä¿¡æ¯
    sources_text = _format_sources_text(_pending_search_sources)
    
    # ç»„è£…æœ€ç»ˆæŠ¥å‘Š
    flood_report = FLOOD_REPORT_TEMPLATE.format(
        event=event or "æœªçŸ¥äº‹ä»¶",
        pre_date=pre_date or "å¾…ç¡®å®š",
        peek_date=peek_date or "å¾…ç¡®å®š",
        after_date=after_date or "å¾…ç¡®å®š",
        location=location or "å¾…ç¡®å®š",
        detailed_report=detailed_report,
        sources=sources_text
    )
    
    # ä¿å­˜æ¥æºä¿¡æ¯
    search_sources = _pending_search_sources.copy() if _pending_search_sources else []
    
    # åˆ›å»ºæŠ¥å‘Šå®Œæˆæ¶ˆæ¯
    report_message = AIMessage(content=f"âœ… ä¿¡æ¯å·²ç¡®è®¤ï¼ŒæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼\n\n{flood_report}")
    
    print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œå…± {len(search_sources)} æ¡å‚è€ƒæ¥æº")
    
    return Command(
        goto="__end__",
        update={
            "messages": report_message,
            "event": event,
            "event_description": event_description,
            "flood_report": flood_report,
            "report_document": flood_report,  # åŒæ­¥åˆ°å¯ç¼–è¾‘çš„æ–‡æ¡£
            "pre_date": pre_date,
            "after_date": after_date,
            "peek_date": peek_date,
            "location": location,
            "coordinates": coordinates,
            "bounds": bounds,
            "geojson": geojson,
            "geo_data": geo_data,
            "search_sources": search_sources,
            "stage": "completed",
            "user_confirmed": True,
            "is_valid_flood_query": True,
        }
    )


# ============== æ„å»ºå›¾ ==============

workflow = StateGraph(FloodAgentState)

# æ·»åŠ èŠ‚ç‚¹ - æ¸…æ™°çš„èŒè´£åˆ†ç¦»
workflow.add_node("entry_node", entry_node)           # å…¥å£è·¯ç”±
workflow.add_node("chat_node", chat_node)             # LLM å¯¹è¯ + å·¥å…·è°ƒç”¨
workflow.add_node("tool_node", ToolNode(tools=tools)) # å·¥å…·æ‰§è¡Œ
workflow.add_node("extraction_node", extraction_node) # ä¿¡æ¯æå–
workflow.add_node("confirmation_node", confirmation_node)  # ç”¨æˆ·ç¡®è®¤ (HITL)
workflow.add_node("processing_node", processing_node) # åœ°ç†ç¼–ç  + æŠ¥å‘Šç”Ÿæˆ
# workflow.add_node("__end__", lambda state, config: None)

# è®¾ç½®å…¥å£ç‚¹
workflow.set_entry_point("entry_node")

# æ·»åŠ è¾¹ - å®šä¹‰æµç¨‹
workflow.add_edge("tool_node", "chat_node")  # å·¥å…·æ‰§è¡Œåå›åˆ°èŠå¤©èŠ‚ç‚¹
# ç¼–è¯‘å›¾
checkpointer = MemorySaver()
graph = workflow.compile(checkpointer=checkpointer)


# ============== å›¾ç»“æ„è¯´æ˜ ==============
"""
é‡æ„åçš„å›¾ç»“æ„ (5ä¸ªä¸»è¦èŠ‚ç‚¹):

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   entry_node    â”‚  å…¥å£è·¯ç”±
                    â”‚   (åˆ¤æ–­é˜¶æ®µ)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”Œâ”€â”€â”€â”€â–¶â”‚   chat_node     â”‚â—€â”€â”€â”€â”€â”
              â”‚     â”‚  (LLMå¯¹è¯)       â”‚     â”‚
              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
              â”‚              â”‚              â”‚
              â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
              â”‚    â”‚                   â”‚    â”‚
              â”‚    â–¼                   â–¼    â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   tool_node    â”‚    â”‚ extraction_node â”‚
      â”‚  (å·¥å…·æ‰§è¡Œ)     â”‚    â”‚   (ä¿¡æ¯æå–)    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚                             â”‚
                      â–¼                             â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚confirmation_nodeâ”‚            â”‚    __end__    â”‚
            â”‚   (HITLç¡®è®¤)    â”‚            â”‚   (æ™®é€šç»“æŸ)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                     â”‚
          â–¼                     â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚processing_node  â”‚   â”‚    __end__    â”‚
 â”‚(åœ°ç†ç¼–ç +æŠ¥å‘Š)   â”‚   â”‚   (ç”¨æˆ·å–æ¶ˆ)  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚    __end__    â”‚
 â”‚  (æµç¨‹å®Œæˆ)    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

èŠ‚ç‚¹èŒè´£:
- entry_node: å…¥å£è·¯ç”±ï¼Œåˆ¤æ–­é˜¶æ®µï¼Œå¤„ç†çŠ¶æ€é‡ç½®
- chat_node: LLM å¯¹è¯å¤„ç†ï¼Œå·¥å…·è°ƒç”¨å†³ç­–
- tool_node: æ‰§è¡Œæœç´¢å·¥å…·
- extraction_node: ä» LLM å“åº”æå–ç»“æ„åŒ–æ•°æ®
- confirmation_node: Human-in-the-Loop ç”¨æˆ·ç¡®è®¤
- processing_node: åœ°ç†ç¼–ç  + æŠ¥å‘Šç”Ÿæˆ
"""
